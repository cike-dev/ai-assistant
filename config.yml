# # The config recipe.
# recipe: default.v1

# # The assistant project unique identifier
# # This default value must be replaced with a unique assistant name within your deployment
# assistant_id: placeholder_default

# language: en
# pipeline:
# - name: CompactLLMCommandGenerator
#   llm:
#     model_group: openai-gpt-4o

# # Configuration for Rasa Core.
# policies:
# - name: FlowPolicy
# - name: IntentlessPolicy



# ================================================================ #
# My config recipe
# ================================================================ #
# The config recipe.
recipe: default.v1

# The assistant project unique identifier
# This default value must be replaced with a unique assistant name within your deployment
assistant_id: wlv_chat_assistant

language: en

pipeline:
  # SearchReadyLLMCommandGenerator is better suited for EnterpriseSearch
  # it optimizes RAG-based knowledge retrieval and business flow accuracy 
  # better than CompactLLMCommandGenerator
  
  - name: SearchReadyLLMCommandGenerator
    # prompt_template: prompts/command-generator.jinja2
    user_input:
      max_characters: 512 # default value: 420
    llm:
      model_group: gemini_llm_01 # use LLM model_group ID defined in endpoints.yml
    flow_retrieval:
      # active: false
        # # if flows become complex and plenty, 
        # # comment the line above and uncomment the block below
      turns_to_embed: 1
      should_embed_slots: true
      num_flows: 20
      embeddings:
        model_group: gemini_embedding_01  # Use embedding model id in endpoints.yml



# Configuration for Rasa Core.
policies:
  - name: FlowPolicy
    llm:
      model_group: gemini_llm_02  # Use LLM model id in endpoints.yml

  - name: EnterpriseSearchPolicy
    check_relevancy: true
    vector_store: 
      type: "faiss"
      source: "./docs"
      threshold: 0.7
    llm:
      model_group: gemini_llm_02  # Use LLM model id in endpoints.yml
    embeddings:
      model_group: gemini_embedding_02  # Use embedding model id in endpoints.yml
    


